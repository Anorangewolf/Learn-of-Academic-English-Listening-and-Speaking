**Wolf Misidentification**:

- This example is used to illustrate how AI can make errors due to biases in its training data.
- The speaker provides a vivid picture of a dog which AI algorithm misclassified as a wolf. He then shows the audience the areas AI pays attention to in the picture, to show that AI misclassified it because the training images of wolves were predominantly set in snow.
- *The comparison is fairly intuitive and impressive*.
- *The speaker mentioned the picture multiple times in the following presentation*. On the one hand, this make a deeper impression on the audience; On the other hand, the precondition is that the eample itself needs to be impressive enough.

**Personal Experience**:

- The speaker’s personal story about driving in snowy conditions to illustrate the concept of AI reliability adds a tangible layer to the abstract idea of AI systems making mistakes.
- This story is not only vivid but also serves to engage the audience on a personal level.
- By sharing his own experience, the speaker builds a connection with the audience.

**Questions**:

- The speaker uses questions like “Who here is scared of killer robots?” and “Why would the judges trust it if it seems to exhibit bias?”
- These questions draw the audience in and prompt them to consider the ethical and practical issues surrounding AI systems.
